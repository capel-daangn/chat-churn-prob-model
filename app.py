"""
Interactive Streamlit Dashboard for Chat Churn Prediction
Real-time prediction and SHAP explanations
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap
import torch
from transformers import AutoTokenizer, AutoModel

# Import from src
from src.train import ChurnModelTrainer
from src.utils import calculate_sentiment_score, calculate_exit_intent_score
from src.shap_analysis import ShapAnalyzer


# Page config
st.set_page_config(
    page_title="ì±„íŒ… ì´íƒˆ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ’¬",
    layout="wide"
)

# Cache heavy operations
@st.cache_resource
def load_model():
    """Load trained model"""
    trainer = ChurnModelTrainer()
    trainer.load_model()
    return trainer

@st.cache_resource
def load_bert_model():
    """Load DistilBERT model"""
    model_name = "distilbert-base-multilingual-cased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    model.eval()
    return tokenizer, model

@st.cache_resource
def load_shap_explainer(_trainer):
    """Load SHAP explainer"""
    analyzer = ShapAnalyzer()
    analyzer.trainer = _trainer
    X_train, _, _, _ = analyzer.load_model_and_data()
    analyzer.create_explainer(X_train)
    return analyzer

@st.cache_data
def load_validation_data():
    """Load validation dataset"""
    analyzer = ShapAnalyzer()
    X_train, X_valid, y_train, y_valid = analyzer.load_model_and_data()

    # Load original messages
    config = analyzer.config
    df = pd.read_csv(config['paths']['raw_data'])

    from sklearn.model_selection import train_test_split
    _, df_valid = train_test_split(
        df,
        test_size=config['training']['test_size'],
        random_state=config['training']['random_state'],
        stratify=df['label']
    )

    return X_valid, y_valid, df_valid.reset_index(drop=True)


def get_text_embedding(text, tokenizer, model):
    """Get DistilBERT embedding for text"""
    with torch.no_grad():
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=64,
            padding='max_length'
        )
        outputs = model(**inputs)
        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
    return embedding


def create_features_from_text(text, dt_prev_sec=60, reaction=0):
    """Create feature vector from text input"""
    # Load models
    tokenizer, bert_model = load_bert_model()

    # Get embedding
    embedding = get_text_embedding(text, tokenizer, bert_model)

    # Calculate meta features
    msg_len = len(text)
    sentiment_score = calculate_sentiment_score(text)
    exit_intent_score = calculate_exit_intent_score(text)

    # Combine features
    meta_features = np.array([
        msg_len,
        dt_prev_sec,
        sentiment_score,
        reaction,
        exit_intent_score
    ])

    features = np.concatenate([embedding, meta_features])

    return features, {
        'msg_len': msg_len,
        'dt_prev_sec': dt_prev_sec,
        'sentiment_score': sentiment_score,
        'reaction': reaction,
        'exit_intent_score': exit_intent_score
    }


def main():
    st.title("ğŸ’¬ ì±„íŒ… ì´íƒˆ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")
    st.markdown("DistilBERT + LightGBM ê¸°ë°˜ ì‹¤ì‹œê°„ ì´íƒˆ í™•ë¥  ì˜ˆì¸¡ ë° SHAP ì„¤ëª…")

    # Sidebar
    st.sidebar.header("ì„¤ì •")
    mode = st.sidebar.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ì‹¤ì‹œê°„ ì˜ˆì¸¡", "ê²€ì¦ ë°ì´í„° íƒìƒ‰", "ëª¨ë¸ ë¶„ì„"]
    )

    # Load model
    with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
        trainer = load_model()

    if mode == "ì‹¤ì‹œê°„ ì˜ˆì¸¡":
        show_real_time_prediction(trainer)
    elif mode == "ê²€ì¦ ë°ì´í„° íƒìƒ‰":
        show_validation_explorer(trainer)
    else:
        show_model_analysis()


def show_real_time_prediction(trainer):
    """Real-time prediction mode"""
    st.header("ğŸ“ ì‹¤ì‹œê°„ ë©”ì‹œì§€ ë¶„ì„")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ë©”ì‹œì§€ ì…ë ¥")
        text = st.text_area(
            "ë¶„ì„í•  ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            value="ê°€ê²© ë„¤ê³  ê°€ëŠ¥í• ê¹Œìš”?",
            height=100
        )

        col_a, col_b = st.columns(2)
        with col_a:
            dt_prev_sec = st.slider("ì´ì „ ë©”ì‹œì§€ì™€ ì‹œê°„ ì°¨ì´ (ì´ˆ)", 0, 3600, 60)
        with col_b:
            reaction = st.selectbox("ë°˜ì‘ ì—¬ë¶€", [0, 1], format_func=lambda x: "ìˆìŒ" if x else "ì—†ìŒ")

    with col2:
        st.subheader("ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
        if st.button("ê¸ì • ë©”ì‹œì§€"):
            text = "ë„¤ ì¢‹ìŠµë‹ˆë‹¤! êµ¬ë§¤í• ê²Œìš”"
        if st.button("ë¶€ì • ë©”ì‹œì§€"):
            text = "ì£„ì†¡í•˜ì§€ë§Œ ë‹¤ì‹œ ìƒê°í•´ë³¼ê²Œìš”"
        if st.button("ì• ë§¤í•œ ë©”ì‹œì§€"):
            text = "..."

    if st.button("ğŸ” ë¶„ì„ ì‹¤í–‰", type="primary"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            # Create features
            features, meta_info = create_features_from_text(text, dt_prev_sec, reaction)

            # Predict
            prob = trainer.predict(features.reshape(1, -1))[0]

            # Display results
            st.markdown("---")
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")

            # Probability gauge
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("ì´íƒˆ í™•ë¥ ", f"{prob*100:.1f}%")
                if prob > 0.7:
                    st.error("âš ï¸ ë†’ì€ ì´íƒˆ ìœ„í—˜")
                elif prob > 0.4:
                    st.warning("âš¡ ì¤‘ê°„ ì´íƒˆ ìœ„í—˜")
                else:
                    st.success("âœ… ë‚®ì€ ì´íƒˆ ìœ„í—˜")

            with col2:
                st.metric("ê°ì • ì ìˆ˜", f"{meta_info['sentiment_score']:.2f}")

            with col3:
                st.metric("ì¢…ë£Œ ì˜ë„", f"{meta_info['exit_intent_score']:.2f}")

            # Meta features
            st.subheader("ğŸ“‹ ë©”íƒ€ í”¼ì²˜")
            meta_df = pd.DataFrame([meta_info])
            st.dataframe(meta_df, use_container_width=True)

            # SHAP explanation
            st.subheader("ğŸ”¬ SHAP ì„¤ëª… (ëª¨ë¸ì´ ì™œ ì´ë ‡ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€)")

            with st.spinner("SHAP ê°’ ê³„ì‚° ì¤‘..."):
                analyzer = load_shap_explainer(trainer)
                shap_values = analyzer.explainer.shap_values(features.reshape(1, -1))

                if isinstance(shap_values, list):
                    shap_values = shap_values[1]

                # Create explanation
                explanation = shap.Explanation(
                    values=shap_values[0],
                    base_values=analyzer.explainer.expected_value,
                    data=features,
                    feature_names=analyzer.feature_names
                )

                # Waterfall plot
                fig, ax = plt.subplots(figsize=(10, 6))
                shap.waterfall_plot(explanation, max_display=15, show=False)
                st.pyplot(fig)
                plt.close()


def show_validation_explorer(trainer):
    """Validation data explorer"""
    st.header("ğŸ“‚ ê²€ì¦ ë°ì´í„° íƒìƒ‰")

    # Load data
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        X_valid, y_valid, df_valid = load_validation_data()
        preds = trainer.predict(X_valid)

    st.success(f"âœ“ {len(df_valid)}ê°œ ë©”ì‹œì§€ ë¡œë“œ ì™„ë£Œ")

    # Filters
    col1, col2, col3 = st.columns(3)

    with col1:
        filter_label = st.selectbox("ì‹¤ì œ ë¼ë²¨", ["ì „ì²´", "ì´íƒˆ (1)", "ìœ ì§€ (0)"])
    with col2:
        filter_sender = st.selectbox("ë°œì‹ ì", ["ì „ì²´", "buyer", "seller"])
    with col3:
        pred_threshold = st.slider("ì˜ˆì¸¡ í™•ë¥  ìµœì†Œê°’", 0.0, 1.0, 0.0)

    # Apply filters
    mask = np.ones(len(df_valid), dtype=bool)

    if filter_label != "ì „ì²´":
        label_val = 1 if "ì´íƒˆ" in filter_label else 0
        mask &= (y_valid == label_val)

    if filter_sender != "ì „ì²´":
        mask &= (df_valid['sender_role'] == filter_sender)

    mask &= (preds >= pred_threshold)

    # Filtered data
    filtered_df = df_valid[mask].copy()
    filtered_df['churn_prob'] = preds[mask]
    filtered_df['actual_label'] = y_valid[mask]

    st.write(f"í•„í„°ë§ëœ ë©”ì‹œì§€: {len(filtered_df)}ê°œ")

    # Sort by prediction
    sort_by = st.radio("ì •ë ¬", ["ì´íƒˆ í™•ë¥  ë†’ì€ ìˆœ", "ì´íƒˆ í™•ë¥  ë‚®ì€ ìˆœ"], horizontal=True)
    ascending = "ë‚®ì€" in sort_by
    filtered_df = filtered_df.sort_values('churn_prob', ascending=ascending)

    # Display messages
    st.subheader("ë©”ì‹œì§€ ëª©ë¡")

    for idx, row in filtered_df.head(20).iterrows():
        with st.expander(
            f"[{row['churn_prob']*100:.1f}%] {row['content'][:50]}..."
        ):
            col1, col2 = st.columns([2, 1])

            with col1:
                st.write(f"**ë©”ì‹œì§€**: {row['content']}")
                st.write(f"**ë°œì‹ ì**: {row['sender_role']}")
                st.write(f"**ì‹¤ì œ ë¼ë²¨**: {'ì´íƒˆ' if row['actual_label'] == 1 else 'ìœ ì§€'}")

            with col2:
                st.metric("ì˜ˆì¸¡ í™•ë¥ ", f"{row['churn_prob']*100:.1f}%")
                st.metric("ë©”ì‹œì§€ ê¸¸ì´", int(row['msg_len']))


def show_model_analysis():
    """Model analysis mode"""
    st.header("ğŸ”¬ ëª¨ë¸ ë¶„ì„")

    tab1, tab2, tab3 = st.tabs(["í”¼ì²˜ ì¤‘ìš”ë„", "SHAP ë¶„ì„", "ì„±ëŠ¥ ì§€í‘œ"])

    with tab1:
        st.subheader("í”¼ì²˜ ì¤‘ìš”ë„")
        try:
            from PIL import Image
            img = Image.open("models/feature_importance.png")
            st.image(img, use_container_width=True)
        except:
            st.warning("í”¼ì²˜ ì¤‘ìš”ë„ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € evaluate.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

    with tab2:
        st.subheader("SHAP Summary Plot")
        try:
            from PIL import Image
            img = Image.open("models/shap_summary.png")
            st.image(img, use_container_width=True)
        except:
            st.warning("SHAP ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”: `python -m src.shap_analysis`")

    with tab3:
        st.subheader("ëª¨ë¸ ì„±ëŠ¥ ê³¡ì„ ")
        try:
            from PIL import Image
            img = Image.open("models/evaluation_curves.png")
            st.image(img, use_container_width=True)
        except:
            st.warning("í‰ê°€ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € evaluate.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
